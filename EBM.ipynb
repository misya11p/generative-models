{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# エネルギーベースモデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from IPython.display import display\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('mps')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch shape: torch.Size([64, 1, 28, 28])\n",
      "width: 28\n",
      "height: 28\n",
      "image size: 784\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "dataset = MNIST(\n",
    "    root=\"data/\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor()\n",
    ")\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "sample_x, _ = next(iter(dataloader))\n",
    "w, h = sample_x.shape[2:]\n",
    "image_size = w * h\n",
    "print(\"batch shape:\", sample_x.shape)\n",
    "print(\"width:\", w)\n",
    "print(\"height:\", h)\n",
    "print(\"image size:\", image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnergyModel(nn.Module):\n",
    "    def __init__(self, image_size=image_size):\n",
    "        super().__init__()\n",
    "        self.image_size = image_size\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(image_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.image_size)\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, n_iter=100, n_images=batch_size):\n",
    "    model.eval()\n",
    "    z = torch.randn(n_images, image_size, device=device)\n",
    "    z.requires_grad = True\n",
    "    optimizer = optim.Adam([z], lr=1e-3)\n",
    "    for _ in range(n_iter):\n",
    "        print(_)\n",
    "        z = F.sigmoid(z)\n",
    "        optimizer.zero_grad()\n",
    "        energy = model(z).mean()\n",
    "        (-energy).backward()\n",
    "        optimizer.step()\n",
    "    x = F.sigmoid(z)\n",
    "    return x.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(model, n_rows=1, n_cols=8, size=64):\n",
    "    images = generate(model, n_images=n_rows*n_cols)\n",
    "    images = transforms.Resize(size)(images)\n",
    "    img = torchvision.utils.make_grid(images, n_cols)\n",
    "    img = transforms.functional.to_pil_image(img)\n",
    "    display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optim, n_epochs):\n",
    "    for n in range(n_epochs):\n",
    "        losses = []\n",
    "        for (x_real, _) in dataloader:\n",
    "            x_real = x_real.to(device)\n",
    "            x_fake = generate(model)\n",
    "\n",
    "            out_real = model(x_real)\n",
    "            out_fake = model(x_fake)\n",
    "            loss = out_fake.mean() - out_real.mean()\n",
    "            loss.backward()\n",
    "            losses.append(loss.item())\n",
    "            optim.step()\n",
    "        print(f\"{n}epoch loss: {sum(losses)/len(losses)}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EnergyModel().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m draw(model)\n",
      "Cell \u001b[0;32mIn[26], line 2\u001b[0m, in \u001b[0;36mdraw\u001b[0;34m(model, n_rows, n_cols, size)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdraw\u001b[39m(model, n_rows\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, n_cols\u001b[39m=\u001b[39m\u001b[39m8\u001b[39m, size\u001b[39m=\u001b[39m\u001b[39m64\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     images \u001b[39m=\u001b[39m generate(model, n_images\u001b[39m=\u001b[39;49mn_rows\u001b[39m*\u001b[39;49mn_cols)\n\u001b[1;32m      3\u001b[0m     images \u001b[39m=\u001b[39m transforms\u001b[39m.\u001b[39mResize(size)(images)\n\u001b[1;32m      4\u001b[0m     img \u001b[39m=\u001b[39m torchvision\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mmake_grid(images, n_cols)\n",
      "Cell \u001b[0;32mIn[25], line 11\u001b[0m, in \u001b[0;36mgenerate\u001b[0;34m(model, n_iter, n_images)\u001b[0m\n\u001b[1;32m      9\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     10\u001b[0m     energy \u001b[39m=\u001b[39m model(z)\u001b[39m.\u001b[39mmean()\n\u001b[0;32m---> 11\u001b[0m     (\u001b[39m-\u001b[39;49menergy)\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     12\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     13\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39msigmoid(z)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.11/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.11/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "draw(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
